"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.RealtimeConnection = exports.RealtimeEvents = void 0;
const ws_1 = __importDefault(require("ws"));
const node_events_1 = require("node:events");
/**
 * Events emitted by the RealtimeConnection.
 */
var RealtimeEvents;
(function (RealtimeEvents) {
    /** Emitted when the session is successfully started */
    RealtimeEvents["SESSION_STARTED"] = "session_started";
    /** Emitted when a partial (interim) transcript is available */
    RealtimeEvents["PARTIAL_TRANSCRIPT"] = "partial_transcript";
    /** Emitted when a final transcript is available */
    RealtimeEvents["FINAL_TRANSCRIPT"] = "final_transcript";
    /** Emitted when a final transcript with timestamps is available */
    RealtimeEvents["FINAL_TRANSCRIPT_WITH_TIMESTAMPS"] = "final_transcript_with_timestamps";
    /** Emitted when an error occurs */
    RealtimeEvents["ERROR"] = "error";
    /** Emitted when the WebSocket connection is opened */
    RealtimeEvents["OPEN"] = "open";
    /** Emitted when the WebSocket connection is closed */
    RealtimeEvents["CLOSE"] = "close";
})(RealtimeEvents || (exports.RealtimeEvents = RealtimeEvents = {}));
/**
 * Manages a real-time transcription WebSocket connection.
 *
 * @remarks
 * **Node.js only**: This class uses Node.js-specific WebSocket implementation.
 *
 * @example
 * ```typescript
 * const connection = await client.speechToText.realtime.connect({
 *     modelId: "scribe_realtime_v2",
 *     audioFormat: AudioFormat.PCM_16000,
 *     sampleRate: 16000,
 * });
 *
 * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {
 *     console.log("Session started");
 * });
 *
 * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {
 *     console.log("Partial:", data.transcript);
 * });
 *
 * connection.on(RealtimeEvents.FINAL_TRANSCRIPT, (data) => {
 *     console.log("Final:", data.transcript);
 *     connection.close();
 * });
 *
 * // Send audio data
 * connection.send({ audioBase64: base64String });
 *
 * // Commit and close
 * connection.commit();
  * ```
 */
class RealtimeConnection {
    constructor(sampleRate) {
        this.websocket = null;
        this.eventEmitter = new node_events_1.EventEmitter();
        this.ffmpegProcess = null;
        this.currentSampleRate = 16000;
        this.currentSampleRate = sampleRate;
    }
    /**
     * @internal
     * Used internally by ScribeRealtime to attach the WebSocket after connection is created.
     */
    setWebSocket(websocket) {
        this.websocket = websocket;
        // If WebSocket is already open, emit OPEN event immediately
        if (this.websocket.readyState === ws_1.default.OPEN) {
            this.eventEmitter.emit(RealtimeEvents.OPEN);
        }
        else {
            // Otherwise, wait for the open event
            this.websocket.on("open", () => {
                this.eventEmitter.emit(RealtimeEvents.OPEN);
            });
        }
        this.websocket.on("message", (event) => {
            const data = JSON.parse(event.toString());
            switch (data.message_type) {
                case "session_started":
                    this.eventEmitter.emit(RealtimeEvents.SESSION_STARTED, data);
                    break;
                case "partial_transcript":
                    this.eventEmitter.emit(RealtimeEvents.PARTIAL_TRANSCRIPT, data);
                    break;
                case "final_transcript":
                    this.eventEmitter.emit(RealtimeEvents.FINAL_TRANSCRIPT, data);
                    break;
                case "final_transcript_with_timestamps":
                    this.eventEmitter.emit(RealtimeEvents.FINAL_TRANSCRIPT_WITH_TIMESTAMPS, data);
                    break;
            }
        });
        this.websocket.on("error", (error) => {
            this.eventEmitter.emit(RealtimeEvents.ERROR, error);
        });
        this.websocket.on("close", () => {
            this.eventEmitter.emit(RealtimeEvents.CLOSE);
            this.cleanup();
        });
    }
    /**
     * @internal
     * Used internally by ScribeRealtime to attach ffmpeg process for cleanup.
     */
    setFfmpegProcess(ffmpegProcess) {
        this.ffmpegProcess = ffmpegProcess;
    }
    /**
     * Attaches an event listener for the specified event.
     *
     * @param event - The event to listen for (use RealtimeEvents enum)
     * @param listener - The callback function to execute when the event fires
     *
     * @example
     * ```typescript
     * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {
     *     console.log("Session started", data);
     * });
     *
     * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {
     *     console.log("Partial:", data.transcript);
     * });
     *
     * connection.on(RealtimeEvents.FINAL_TRANSCRIPT, (data) => {
     *     console.log("Final:", data.transcript);
     * });
     * ```
     */
    on(event, listener) {
        this.eventEmitter.on(event, listener);
    }
    /**
     * Removes an event listener for the specified event.
     *
     * @param event - The event to stop listening for
     * @param listener - The callback function to remove
     *
     * @example
     * ```typescript
     * const handler = (data) => console.log(data);
     * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);
     *
     * // Later, remove the listener
     * connection.off(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);
     * ```
     */
    off(event, listener) {
        this.eventEmitter.off(event, listener);
    }
    /**
     * Sends audio data to the transcription service.
     *
     * @param data - Audio data configuration
     * @param data.audioBase64 - Base64-encoded audio data
     * @param data.commit - Whether to commit the transcription after this chunk. You likely want to use connection.commit() instead (default: false)
     * @param data.sampleRate - Sample rate of the audio (default: configured sample rate)
     *
     * @throws {Error} If the WebSocket connection is not open
     *
     * @example
     * ```typescript
     * // Send audio chunk without committing
     * connection.send({
     *     audioBase64: base64EncodedAudio,
     * });
     *
     * // Send audio chunk with custom sample rate
     * connection.send({
     *     audioBase64: base64EncodedAudio,
     *     sampleRate: 16000,
     * });
     * ```
     */
    send(data) {
        var _a, _b;
        if (!this.websocket || this.websocket.readyState !== ws_1.default.OPEN) {
            throw new Error("WebSocket is not connected");
        }
        const message = {
            message_type: "input_audio_chunk",
            audio_base_64: data.audioBase64,
            commit: (_a = data.commit) !== null && _a !== void 0 ? _a : false,
            sample_rate: (_b = data.sampleRate) !== null && _b !== void 0 ? _b : this.currentSampleRate,
        };
        this.websocket.send(JSON.stringify(message));
    }
    /**
     * Commits the transcription, signaling that all audio has been sent.
     * This finalizes the transcription and triggers a FINAL_TRANSCRIPT event.
     *
     * @throws {Error} If the WebSocket connection is not open
     *
     * @remarks
     * Only needed when using CommitStrategy.MANUAL.
     * When using CommitStrategy.VAD, commits are handled automatically by the server.
     *
     * @example
     * ```typescript
     * // Send all audio chunks
     * for (const chunk of audioChunks) {
     *     connection.send({ audioBase64: chunk });
     * }
     *
     * // Finalize the transcription
     * connection.commit();
     * ```
     */
    commit() {
        if (!this.websocket || this.websocket.readyState !== ws_1.default.OPEN) {
            throw new Error("WebSocket is not connected");
        }
        const message = {
            message_type: "input_audio_chunk",
            audio_base_64: "",
            commit: true,
            sample_rate: this.currentSampleRate,
        };
        this.websocket.send(JSON.stringify(message));
    }
    /**
     * Closes the WebSocket connection and cleans up resources.
     * This will terminate any ongoing transcription and stop ffmpeg processes if running.
     *
     * @remarks
     * After calling close(), this connection cannot be reused.
     * Create a new connection if you need to start transcribing again.
     *
     * @example
     * ```typescript
     * connection.on(RealtimeEvents.FINAL_TRANSCRIPT, (data) => {
     *     console.log("Final:", data.transcript);
     *     connection.close();
     * });
     * ```
     */
    close() {
        this.cleanup();
        if (this.websocket) {
            this.websocket.close();
        }
    }
    cleanup() {
        if (this.ffmpegProcess) {
            this.ffmpegProcess.kill();
            this.ffmpegProcess = null;
        }
    }
}
exports.RealtimeConnection = RealtimeConnection;
